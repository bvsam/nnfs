# Neural Networks from Scratch (nnfs)

This program allows a neural network built using basic Python and Numpy to run on provided inputs. It was created to develop a better understanding of how neural networks work.

This project was based off the [neural networks from scratch tutorial](https://www.youtube.com/watch?v=Wo5dMEP_BbI&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3) by Sentdex.

## Features

The neural network uses Numpy whenever possible for more efficient matrix calculations.

So far, the following features of neural networks have been implemented from scratch:

- Dense layers
- ReLU and Softmax activation functions
- Categorical Cross-Entropy Loss
- Forward propagation
- Backpropagation and gradient calculation
- Optimizers with learning rate decay
  - Stochastic Gradient Descent (SGD) optimizer with momentum
  - Adaptive Gradient (Adagrad) optimizer
  - Root Mean Square Propagation (RMSProp) optimizer
  - Adaptive Momentum (Adam) optimizer
- L1 and L2 regularization
- Dropout
